# Gateway Configuration for ada2 Image Generation
#
# This configuration routes all image generation requests to gpu_heavy (ada2)
# running InvokeAI with SDXL models.
#
# Usage:
#   1. Copy to /var/lib/gateway/app/.env on production (macOS ai2)
#   2. Set GATEWAY_BEARER_TOKEN to a secure value
#   3. Ensure ada2 is running InvokeAI on port 7860
#   4. Deploy gateway: cd ai-infra/services/gateway && ./scripts/deploy.sh

# === Core Gateway Settings ===
GATEWAY_BEARER_TOKEN=your-secure-token-here
GATEWAY_HOST=127.0.0.1
GATEWAY_PORT=8800

# === Image Generation Backend ===
# Route images to gpu_heavy (ada2 with RTX 6000 Ada)
IMAGES_BACKEND=http_openai_images
IMAGES_BACKEND_CLASS=gpu_heavy
IMAGES_HTTP_BASE_URL=http://ada2:7860
IMAGES_OPENAI_MODEL=sd-xl-base-1.0

# Image storage (content-addressed, served via /ui/images/)
UI_IMAGE_DIR=/var/lib/gateway/data/ui_images

# === Backend Routing (Optional Overrides) ===
# If you need to force routing for specific models:
# ROUTER_ENABLE_POLICY=true

# === Health Checking ===
# Health checker runs automatically in background
# Checks backends every 30s for /healthz and /readyz

# === Other Backends (for reference) ===
# These are configured in backends_config.yaml, included here for visibility:
#
# local_mlx (ai2, macOS):
#   - Capabilities: chat, embeddings
#   - No longer used for images
#
# gpu_fast (ai1, RTX 5060 Ti):
#   - Capabilities: chat, embeddings
#
# gpu_heavy (ada2, RTX 6000 Ada):
#   - Capabilities: images
#   - Concurrency limit: 2
#   - This is the ONLY backend for image generation

# === Monitoring ===
# Check gateway status:
#   curl http://127.0.0.1:8800/v1/gateway/status -H "Authorization: Bearer $TOKEN"
#
# Check backend health:
#   curl http://ada2:7860/healthz

# === Advanced: Alternative Models ===
# For faster generation (SD 1.5 instead of SDXL):
# IMAGES_OPENAI_MODEL=sd-v1-5

# For specific InvokeAI model:
# IMAGES_OPENAI_MODEL=your-model-name-from-invokeai
